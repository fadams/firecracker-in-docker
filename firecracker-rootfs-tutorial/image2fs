#!/bin/bash
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/
set -euo pipefail

# Use the same demo image as the other examples in the tutorial
# for consistency. We could however avoid docker if the image
# is held in a repository, if so replace these three lines with
# IMAGE=<repo>/<image-name>
IMAGE=focal-demo
docker save $IMAGE > ${IMAGE}.tar
IMAGE=${IMAGE}.tar


SIZE=250
# To create a Docker style 12 hex character hostname use
# the following:
# HOSTNAME=$(tr -dc 'a-f0-9' < /dev/urandom | head -c12)
HOSTNAME="firecracker"
MOUNTPOINT=rootfs
FILESYSTEM=rootfs.ext4


# Parse the registry URL, normalised image name and tag
# from the supplied image name, defaulting to the Docker
# Hub registry if registry is not specified in the usual
# image name convention e.g. my-registry-host:443/my-image.
# https://docs.docker.com/engine/reference/commandline/tag/#extended-description
# https://stackoverflow.com/questions/37861791/how-are-docker-image-names-parsed
parse_image_name() {
    local image=$1
    local prefix=$([ -z "${image##*/*}" ] && echo $image | cut -d"/" -f1)
    if [[ $prefix =~ [\.:]|localhost ]]; then
        # Remove registry prefix to normalise image name
        image=$(echo $image | cut -d"/" -f2)
        local registry_URL="https://$prefix"
    else
        # Add "library" prefix if image isn't namespaced
        [ -z $prefix ] && image="library/$image"
        registry_URL="https://registry-1.docker.io"
    fi

    # Parse tag and image from normalised image name
    if [ -z "${image##*:*}" ]; then
        local tag=$(echo $image | cut -d":" -f2)
        image=$(echo $image | cut -d":" -f1)
    else
        local tag="latest"
    fi

    echo "$registry_URL $image $tag"
}


# Get the bearer authentication token needed to pull the image.
# https://docs.docker.com/registry/spec/auth/jwt/
# https://docs.docker.com/registry/spec/auth/token/#example
# Note that the url/service values here relate to Docker Hub and
# won't be valid for private registries that use bearer token
# TODO AWS ECR for example has its own GetAuthorizationToken API.
# https://docs.aws.amazon.com/AmazonECR/latest/APIReference/API_GetAuthorizationToken.html
# that may also be accessed via the AWS CLI get-authorization-token command
# https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/get-authorization-token.html
# aws ecr get-authorization-token
get_dockerhub_auth_token() {
    local auth_URL="https://auth.docker.io"
    local service="registry.docker.io"
    local token=$(curl -fsSL "${auth_URL}/token?service=${service}&scope=repository:${image}:pull" | jq --raw-output .token)
    echo "$token"
}


# Make curl work with self-signed certs
# https://curl.se/docs/sslcerts.html
# N.B. this tells curl to *not* verify the peer, which
# might well be fine for trusted private registries.
# A more secure option is to use --cacert [file] or
# add the CA cert for your registry to the existing
# default CA certificate store e.g. /etc/ssl/certs
curl_ca_verification() {
    [[ $1 != "https://registry-1.docker.io" ]] && echo "--insecure"
}


# Get the image manifest document from the image registry.
# The manifests query could return a manifest list as per:
# https://docs.docker.com/registry/spec/manifest-v2-2/
# If so we extract the digest that relates to linux amd64
# and use that to call get_manifest again.
get_manifest() {
    local URL=$1
    local token=$2
    local image=$3
    local digest=$4

    local query=$(curl -fsSL $(curl_ca_verification $URL) \
        -H "Authorization: Bearer $token" \
        -H 'Accept: application/vnd.docker.distribution.manifest.list.v2+json' \
        -H 'Accept: application/vnd.docker.distribution.manifest.v1+json' \
        -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' \
        "${URL}/v2/${image}/manifests/${digest}")

    if [[ $(echo $query | jq --raw-output 'has("manifests")') == true ]]; then
        digest=$(echo $query | jq --raw-output '.manifests[] | select(.platform.architecture=="amd64") | select(.platform.os=="linux") | .digest')
        get_manifest $URL $token $image $digest
    else
        echo $query
    fi
}


# Get image blob (e,g, config or layer) from the registry.
get_blob() {
    local URL=$1
    local token=$2
    local image=$3
    local digest=$4

    curl -fsSL $(curl_ca_verification $URL) \
        -H "Authorization: Bearer $token" \
        "${URL}/v2/${image}/blobs/${digest}"
}


# Some images might have been created with some directories set to
# mode 666 or 660 e.g. unwritable even by owner. This can be awkward
# when trying to create a root filesystem as an unprivileged user as
# subsequent layers will be unable to untar into the unwritable
# directory (among other issues). To resolve this we find all such
# unwritable directories and chmod them to make them user writable.
# We return the directories we've found so that we can concatenate
# with those found in other layers and eventually set them back to
# unwritable after we've unpacked the entire image's root filesystem.
chmod_unwritable_dirs() {
    local rootfs=$1
    local unwritable_dirs=$(find $rootfs -type d ! -writable)

    for item in $unwritable_dirs; do chmod u+w $item; done
    echo "$unwritable_dirs"
}


# With some images some files (most notably shadow and gshadow) get
# set unreaable even by the owner. This is usually mod 000 and usually
# the shadow/gshadow files. The idea behind setting /etc/shadow permissions
# to 000 is to protect it from being accessed by daemons, even when running
# as root, by ensuring that access is controlled by the DAC_OVERRIDE capability.
# Unfortunately this makes it impossible for an unpriviliged user to copy
# such files when building the root filesystem, so we make them readable
# here (basically 600 vice 000) and will adjust the permissions back later.
chmod_unreadable_dirs() {
    local rootfs=$1

    for item in $(find $rootfs -type f ! -readable); do
        chmod u+r $item
        if [ -z "${item##*shadow-}" ]; then # Delete shadow/gshadow backups
            rm -f $item
        fi
    done
}


# The OCI layer specification represents deleted files or
# directories with a file prefixed with .wh.
# https://github.com/opencontainers/image-spec/blob/main/layer.md#whiteouts
delete_marked_items() {
    local rootfs=$1

    for item in $(find $rootfs -type f -name ".wh.*"); do
        rm -rf ${item/.wh./} # Remove marked path
        rm -rf $item # Remove marker file
    done
}


# This function is (roughly) equivalent way to docker pull.
# It first parses the supplied image name to recover the
# registry URL, normalised image name and tag. Next it gets
# the bearer authentication token that is required to get the
# image manifest. With the manifest retrieved it may be used
# to find the IDs (digests) of the image layers, which are
# then pulled and unpacked into our root filesystem.
docker_pull() {
    local image=$1
    local rootfs=$2

    # Convert returned value into array to use like a tuple
    local parsed_image_name=($(parse_image_name $image))
    local registry_URL=${parsed_image_name[0]}
    image=${parsed_image_name[1]}
    local tag=${parsed_image_name[2]}

    #echo "registry_URL: $registry_URL"
    #echo "image: $image"
    #echo "tag: $tag"

    echo "Using $([[ $tag == "latest" ]] && echo "default") tag: $tag"
    echo "$tag: Pulling from $image"

    # Get the Docker Hub bearer authentication token needed to pull image.
    # Note that this won't be valid for private registries that use bearer token
    local token=$(get_dockerhub_auth_token)

    # Get the image manifest from the registry
    # https://docs.docker.com/registry/spec/manifest-v2-2/
    local manifest=$(get_manifest $registry_URL $token $image $tag)
    [[ $manifest == "" ]] && exit 1
    #echo $manifest

    # Get the image config from the manifest. There doesn't
    # seem to be a document for this, but it's basically the
    # same as the OCI image configuration schema.
    # https://github.com/opencontainers/image-spec/blob/main/config.md
    local config=$(echo "$manifest" | jq --raw-output .config.digest)
    config=$(get_blob $registry_URL $token $image $config)
    [[ $config == "" ]] && exit 1

    #echo $config > config.json # Raw JSON
    #echo $config | jq --raw-output . > config.json # Pretty print with jq

    # Get the layers from the manifest
    local layers=$(echo "$manifest" | jq --raw-output .layers[])
    local layer_digests=$(echo "$layers" | jq --raw-output .digest)
    local sizes=$(echo "$layers" | jq --raw-output .size)
    sizes=(${sizes})  # Get layer sizes as an array
    #echo $layer_digests

    local unwritable_dirs=() # Used so we can restore original permissions
    for digest in $layer_digests; do
        # Convert layer size to MB
        local layer_size=$(echo "scale=2; (${sizes[0]}+5000)/1000000" | bc)
        sizes=(${sizes[@]:1}) # Remove first element using sub-arrays
        echo -en "${digest:7:12}: Downloading ${layer_size}MB"
        get_blob $registry_URL $token $image $digest | tar -xz -C ${rootfs}
        echo -en "\r${digest:7:12}: Pull complete        \n"

        unwritable_dirs+=($(chmod_unwritable_dirs "$rootfs"))
        delete_marked_items "$rootfs"
    done
    echo

    # If there were any unwritable dirs in the layers that we
    # needed to make writable in order to unpack the filesysem,
    # we now restore them back to their original permissions.
    for item in "${unwritable_dirs[@]}"; do chmod u-w $item; done

    chmod_unreadable_dirs "$rootfs"
}


# This function follows a similar approach to our docker_pull
# though in this case we are unpacking the image archive
# exposed by doing docker save. We first extract the manifest
# from the archive and use that to get the names of the config
# and layers files, which we then use to extract those objects
# from the image archive. We use tar xOf to extract to stdout
docker_load() {
    local image=$1
    local rootfs=$2
    local decompress=""
    [ -z "${image##*.tar.gz*}" ] && decompress="z"
    echo "Loading image from from $image"

    # Get the image manifest from the registry. This is
    # similar, but not identical to the manifest described in: 
    # https://docs.docker.com/registry/spec/manifest-v2-2/
    local manifest=$(tar -${decompress}xOf $image manifest.json)
    #echo $manifest

    # Get the image config from the manifest.
    local config=$(echo "$manifest" | jq --raw-output .[0].Config)
    config=$(tar -${decompress}xOf $image $config)
    [[ $config == "" ]] && exit 1

    #echo $config > config.json # Raw JSON
    #echo $config | jq --raw-output . > config.json # Pretty print with jq

    # Get the layers from the manifest
    local layers=$(echo "$manifest" | jq --raw-output .[0].Layers[])
    #echo $layers

    local unwritable_dirs=() # Used so we can restore original permissions
    for layer in $layers; do
        echo -en "${layer:0:12}: Untarring"
        tar -${decompress}xOf $image $layer | tar -x -C ${rootfs}
        echo -en "\r${layer:0:12}: Untar complete        \n"

        unwritable_dirs+=($(chmod_unwritable_dirs "$rootfs"))
        delete_marked_items "$rootfs"
    done
    echo

    # If there were any unwritable dirs in the layers that we
    # needed to make writable in order to unpack the filesysem,
    # we now restore them back to their original permissions.
    for item in "${unwritable_dirs[@]}"; do chmod u-w $item; done

    chmod_unreadable_dirs "$rootfs"
}


# Create a directory for our filesystem
mkdir -p $MOUNTPOINT

if [ -z "${IMAGE##*.tar*}" ]; then
    docker_load $IMAGE $MOUNTPOINT
else
    docker_pull $IMAGE $MOUNTPOINT
fi

# Create /etc/hostname and /etc/resolv.conf in rootfs.
# Overwritten by firestarter so included here
# for illustration purposes only
#echo $HOSTNAME | sudo tee $MOUNTPOINT/etc/hostname >/dev/null
#sudo cp /run/systemd/resolve/resolv.conf $MOUNTPOINT/etc/resolv.conf
#sudo chmod 644 $MOUNTPOINT/etc/hostname $MOUNTPOINT/etc/resolv.conf

# Estimate required minimum rootfs size (disk usage + 20%)
FILESYSTEM_SIZE=$(du -sh $MOUNTPOINT | grep -o '[0-9]*')
FILESYSTEM_SIZE=$((FILESYSTEM_SIZE + (FILESYSTEM_SIZE / 5)))
# If requested size is less than estimated minimum warn and adjust.
if [ "$FILESYSTEM_SIZE" -gt "$SIZE" ]; then
    echo "Warning: estimated rootfs size of ${FILESYSTEM_SIZE}MB > configured size of ${SIZE}MB, resizing"
    SIZE=$FILESYSTEM_SIZE
fi

# Create filesystem from directory contents using mkfs.ext4
# Use fakeroot to ensure filesystem has root:root ownership
# https://manpages.debian.org/buster/fakeroot/fakeroot.1.en.html
# https://man7.org/linux/man-pages/man8/mke2fs.8.html
rm -f $FILESYSTEM
fakeroot sh -c "mkfs.ext4 -L '' -N 0 -d ${MOUNTPOINT} -m 5 -r 1 ${FILESYSTEM} ${SIZE}M"

# Make unwritable directories writable so that we may remove the directory
chmod_unwritable_dirs "$MOUNTPOINT" > /dev/null
rm -rf $MOUNTPOINT
rm -f $IMAGE

